{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "dataset_folder_path = 'data'\n",
    "dataset_filename = 'text8.zip'\n",
    "dataset_name = 'Text8 Dataset'\n",
    "\n",
    "class DLProgess(tqdm):\n",
    "    last_block = 0\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "        \n",
    "if not isfile(dataset_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc=dataset_name) as pbar:\n",
    "        urlretrieve(\n",
    "                'http://mattmahoney.net/dc/text8.zip',\n",
    "                dataset_filename,\n",
    "                pbar.hook)\n",
    "        \n",
    "if not isdir(dataset_folder_path):\n",
    "    with zipfile.ZipFile(dataset_filename) as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder_path)\n",
    "        \n",
    "with open('data/text8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst']\n"
     ]
    }
   ],
   "source": [
    "def proprocess(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' <PREIOD> ')\n",
    "    text = text.replace(',', ' <COMMA> ')\n",
    "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';', ' <SEMICOLON> ')\n",
    "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')', ' <RIGHT-PAREN> ')\n",
    "    text = text.replace('--', '< HYPHENS >')\n",
    "    text = text.replace('?', '< QUESTION_MARK >')\n",
    "    words = text.replace(':', ' <COLON> ')\n",
    "    words = text.split()\n",
    "    \n",
    "    word_counts = Counter(words)\n",
    "    trimmed_words = [word for word in words if word_counts[word] > 5]\n",
    "    \n",
    "    return trimmed_words\n",
    "\n",
    "words = utils.preprocess(text)\n",
    "print (words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 16680599\n",
      "Unique words: 63641\n"
     ]
    }
   ],
   "source": [
    "print (\"Total words: {}\".format(len(words)))\n",
    "print (\"Unique words: {}\".format(len(set(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_tables(words):\n",
    "    word_counts = Counter(words)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab = utils.create_lookup_tables(words)\n",
    "int_words = [vocab_to_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1e-5\n",
    "count_words = Counter(int_words)\n",
    "total_words = len(int_words)\n",
    "freq_words = {word: count_word/total_words for word, count_word in count_words.items()}\n",
    "p_drop = {word: 1-np.sqrt(t/freq) for word, freq in freq_words.items()}\n",
    "\n",
    "train_words = [word for word, p in p_drop.items() if random.random() < p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(words, idx, window_size=5):\n",
    "#     sub_win = random.randint(1, window_size+1)\n",
    "    sub_win = window_size//2\n",
    "    start = idx - sub_win if (idx - sub_win) > 0 else 0\n",
    "    end = idx + sub_win\n",
    "    target_words = set(words[start: idx] + words[idx+1: end+1])\n",
    "    \n",
    "    return list(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, batch_size, window_size=5):\n",
    "    n_batches = len(words) // batch_size\n",
    "    \n",
    "    # only full batches\n",
    "    words = words[: n_batches*batch_size]\n",
    "    for idx in range(0, len(words), batch_size):\n",
    "        x, y = [], []\n",
    "        batch = words[idx: idx+batch_size]\n",
    "        for ii in range(window_size//2, len(batch)-window_size//2):\n",
    "            batch_x = batch[ii]\n",
    "            batch_y = get_target(batch, ii, window_size)\n",
    "            y.extend(batch_y)\n",
    "            x.extend([batch_x])\n",
    "        \n",
    "            yield batch_x, batch_y\n",
    "#         yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, windows_size, n_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden = nn.Linear(embedding_dim, n_hidden)\n",
    "        self.output = nn.Linear(n_hidden, (windows_size-1)*vocab_size)\n",
    "        self.windows_size = windows_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x)\n",
    "        h = self.hidden(emb)\n",
    "        h = F.relu(h)\n",
    "        out = self.output(h)\n",
    "        log_prob = F.log_softmax(out, dim=1).view(self.windows_size-1, -1)\n",
    "        \n",
    "        return log_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (4) to match target batch_size (24).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3f2075c2df2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#         print (out, y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\YangY\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\YangY\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\YangY\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1786\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[1;32m-> 1788\u001b[1;33m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[0;32m   1789\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (24)."
     ]
    }
   ],
   "source": [
    "epoches = 100\n",
    "window_size = 5\n",
    "hidden = 128\n",
    "vocab_size = len(vocab_to_int)\n",
    "embedding_dim = 100\n",
    "\n",
    "batch_size = 10\n",
    "net = Net(vocab_size, embedding_dim, window_size, hidden)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
    "net = net.to('cuda')\n",
    "for epoch in range(epoches):\n",
    "    running_loss = 0\n",
    "    \n",
    "    batches = get_batches(train_words, batch_size, window_size)\n",
    "    for x, y in batches:\n",
    "#         print (x, y)\n",
    "        x, y = torch.LongTensor([x]).to('cuda'), torch.LongTensor(y).to('cuda')\n",
    "#         print (x)\n",
    "        out = net(x)\n",
    "#         print (out, y)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        running_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print ('Loss: {:.6f}'.format(running_loss/ len(vocab_to_int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.3538, -4.6007, -5.0398, -4.9648, -4.6309, -4.4803, -4.7688, -4.9358,\n",
      "         -4.1981, -4.9230, -4.2645, -4.2247, -4.5440, -3.8349, -5.1897, -4.6669,\n",
      "         -4.2760, -4.6739, -5.0728, -4.5043, -4.7013, -4.3932, -4.4034, -3.9276,\n",
      "         -5.0377, -5.1229, -4.6699, -4.8776, -5.1106, -3.9835, -4.6497, -4.8369,\n",
      "         -5.4839, -4.3270, -4.1150, -4.9706, -4.5220, -4.6367, -4.2472, -5.1215,\n",
      "         -4.6386, -5.0091, -5.0965, -4.5019, -4.8320, -4.1742, -4.5657, -5.1686,\n",
      "         -4.3551, -4.2830, -4.8977, -4.5800, -4.8081, -5.1652, -5.0385, -4.4137,\n",
      "         -4.5179, -4.9374, -3.9648, -4.3845, -4.1027, -4.4440, -4.0493, -4.3854,\n",
      "         -4.8065, -4.5743, -4.5261, -5.0209, -4.9812, -5.0853, -4.1536, -5.3433,\n",
      "         -3.8726, -4.8139, -4.7930, -4.7320, -4.7073, -4.1928, -4.5084, -4.0860,\n",
      "         -4.7967, -5.0510, -4.6348, -5.1435, -4.7554, -4.5807, -4.9860, -4.5273,\n",
      "         -4.9976, -4.4065, -4.5494, -4.6530, -5.0937, -4.4996, -4.6472, -4.9710,\n",
      "         -4.0610]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([16])\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "# print(trigrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "#         print (context_idxs)\n",
    "        \n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        print (log_probs)\n",
    "        print (torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        break\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    break\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary 195\n",
      "[('insist', 77)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1644.6528630256653\n",
      "[('insist', 77)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1642.0468792915344\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1639.4606614112854\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1636.8939280509949\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1634.3458337783813\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1631.8149962425232\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1629.3006920814514\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1626.8015265464783\n",
      "[('victims', 160)]\n",
      "[('afflictions”', 83)]\n",
      "[('Alice', 88)]\n",
      "1624.3170342445374\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('Alice', 88)]\n",
      "1621.8456707000732\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('Alice', 88)]\n",
      "1619.3868370056152\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('Alice', 88)]\n",
      "1616.9397797584534\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('Alice', 88)]\n",
      "1614.5040121078491\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1612.078724861145\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1609.6640033721924\n",
      "[('victims', 160)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1607.258475780487\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1604.862317085266\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1602.4741640090942\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1600.0937128067017\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1597.7206115722656\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1595.3549480438232\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1592.9962816238403\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1590.6436586380005\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1588.2970414161682\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1585.9564876556396\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1583.622215270996\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1581.293930053711\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1578.9717526435852\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1576.6558113098145\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1574.3456387519836\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1572.0417823791504\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1569.7439708709717\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1567.4522094726562\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1565.1656694412231\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1562.885826587677\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1560.6122889518738\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1558.3445715904236\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1556.0827550888062\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1553.8284902572632\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1551.5830092430115\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1549.3454070091248\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1547.1152906417847\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1544.892807006836\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1542.6782689094543\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1540.472267150879\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1538.275059223175\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1536.0863065719604\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1533.9064874649048\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1531.736005783081\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1529.5747265815735\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1527.4216604232788\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1525.278793811798\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1523.1463723182678\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1521.0237174034119\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1518.9103364944458\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1516.8057103157043\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1514.7105298042297\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1512.6240754127502\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1510.546242237091\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1508.47562789917\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1506.411943435669\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1504.3556261062622\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1502.3066639900208\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1500.2643947601318\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1498.2280569076538\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1496.1972222328186\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1494.1707563400269\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1492.1496992111206\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1490.1324434280396\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1488.1184921264648\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1486.1071782112122\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1484.0982887744904\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1482.0911149978638\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1480.0850186347961\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1478.0799543857574\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1476.0748331546783\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1474.0697691440582\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1472.0635888576508\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1470.055698633194\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1468.045994758606\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1466.0345628261566\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1464.020273923874\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1462.0025479793549\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1459.9823334217072\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1457.9589059352875\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "1455.9326901435852\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1453.9028751850128\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1451.8692286014557\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1449.8308873176575\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1447.7870309352875\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1445.7388880252838\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1443.6858112812042\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1441.6275565624237\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1439.5634343624115\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1437.4942436218262\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1435.418612241745\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1433.338366508484\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1431.2513599395752\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1429.1585562229156\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1427.05917429924\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1424.95352101326\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1422.8404183387756\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1420.720309495926\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1418.5925812721252\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1416.4567894935608\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1414.3135149478912\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1412.1625492572784\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1410.0035853385925\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1407.835746049881\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1405.6600098609924\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1403.4757566452026\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1401.2828760147095\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1399.0816404819489\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1396.872106552124\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1394.6535995006561\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1392.4260647296906\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1390.189358472824\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1387.9437954425812\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1385.688712835312\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1383.4254684448242\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1381.1520192623138\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1378.8703861236572\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1376.5791583061218\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1374.2786684036255\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1371.9683451652527\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1369.6487917900085\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1367.3194057941437\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1364.9803895950317\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1362.6310803890228\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1360.2716982364655\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1357.9024057388306\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1355.523547410965\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1353.1354932785034\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1350.7374651432037\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1348.3298077583313\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1345.9122385978699\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1343.4842631816864\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1341.0477120876312\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1338.6011497974396\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1336.1449382305145\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1333.679814338684\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1331.203334569931\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1328.7175154685974\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1326.2227215766907\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1323.717203617096\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "1321.2022116184235\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1318.6783621311188\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1316.1447756290436\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1313.6020514965057\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1311.0500280857086\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1308.4881281852722\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1305.9169051647186\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1303.3368065357208\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1300.7471165657043\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1298.1479094028473\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1295.5397336483002\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1292.9225163459778\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1290.2957260608673\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1287.6602215766907\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1285.0158421993256\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1282.3623507022858\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1279.7003977298737\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1277.0298194885254\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1274.350287437439\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1271.6611042022705\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1268.9646122455597\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1266.2590084075928\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1263.544315814972\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1260.8214497566223\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1258.090410709381\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1255.3515949249268\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1252.6041793823242\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1249.85027551651\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1247.0870883464813\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1244.3159310817719\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1241.537742972374\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1238.7509089708328\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1235.9558148384094\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1233.1532777547836\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1230.342362523079\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1227.5248135328293\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1224.6990140676498\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1221.8657087087631\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1219.0255860090256\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1216.1780806779861\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1213.3232644796371\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1210.462550520897\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1207.594836115837\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1204.7201095819473\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1201.8390308618546\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1198.9510425329208\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1196.0569405555725\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1193.1558783054352\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1190.2481709718704\n",
      "[('the', 136)]\n",
      "[('the', 136)]\n",
      "[('in', 31)]\n",
      "1187.3348315954208\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1184.4151130914688\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1181.4904078245163\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1178.559301495552\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1175.6234322786331\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1172.6818696260452\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1169.733753323555\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1166.7813880443573\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1163.8246213197708\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1160.8632588386536\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1157.8975721597672\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1154.9256805181503\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1151.9491900205612\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1148.9685953855515\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1145.9830508232117\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1142.9935898780823\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1139.9992002248764\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1137.0018764734268\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1134.000330209732\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1130.9936915636063\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1127.9840734004974\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1124.9701396226883\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1121.9522079229355\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1118.9310020208359\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1115.9070638418198\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1112.8789026737213\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1109.8480876684189\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1106.815300822258\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1103.7789858579636\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1100.7410861253738\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1097.700589299202\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1094.6570714712143\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1091.6119990348816\n",
      "[('the', 136)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1088.5639580488205\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1085.5144027471542\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1082.4623981714249\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1079.4107276201248\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1076.356255531311\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1073.300673365593\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1070.2445026636124\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1067.1871112585068\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1064.1287542581558\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1061.0696151256561\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1058.0100843906403\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1054.9520145654678\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1051.891571879387\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1048.8333288431168\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1045.7743614912033\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1042.716276049614\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1039.6590538024902\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1036.602844953537\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1033.546672821045\n",
      "[('and', 139)]\n",
      "[('and', 139)]\n",
      "[('in', 31)]\n",
      "1030.4938029050827\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1027.4409960508347\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1024.3897572755814\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1021.3404661417007\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1018.2938244342804\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1015.2490540742874\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1012.2081907987595\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1009.1686110496521\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1006.1316834688187\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1003.0982537269592\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "1000.0680158138275\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in', 31)]\n",
      "997.0416456460953\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "994.017196059227\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "990.9975258111954\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "987.9816936254501\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "984.9692245721817\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "981.9608970880508\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "978.9571114778519\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "975.9581354856491\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "972.9644321203232\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "969.9748946428299\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "966.9911109209061\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "964.0126566886902\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "961.0398725271225\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "958.0724025964737\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "955.1109210252762\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "952.1566935777664\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "949.2075334787369\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "946.2651160955429\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "943.3299973011017\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "940.3997954130173\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "937.4788130521774\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "934.5633317232132\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('in', 31)]\n",
      "931.6553353071213\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "928.7548404932022\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "925.8620744943619\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "922.9773411750793\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "920.1013600826263\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "917.2324143648148\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "914.3726065158844\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "911.5204781293869\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "908.6775500774384\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "905.8430194854736\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "903.0173668861389\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "900.2012104988098\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "897.3934344053268\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "894.5955684185028\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "891.8075392246246\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "889.0280194282532\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "886.258504152298\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "883.4988808631897\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "880.749443769455\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "878.0100840330124\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "875.280760884285\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "872.5610280036926\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "869.8522535562515\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "867.1550101041794\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "864.4675084352493\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "861.791291475296\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "859.1260287761688\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "856.4718686342239\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "853.8287402391434\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "851.1967978477478\n",
      "[('and', 139)]\n",
      "[('can', 113)]\n",
      "[('incapacitating', 33)]\n",
      "848.5754051208496\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "845.9662498235703\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "843.3671456575394\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "840.78029692173\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "838.2044122219086\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "835.6418128013611\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "833.0889656543732\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "830.5480415821075\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "828.020504951477\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "825.5033514499664\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "822.9977939128876\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "820.5054898262024\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "818.0241049528122\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "815.5557055473328\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "813.0989357233047\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "810.6548560857773\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "808.2217289209366\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "805.8035374879837\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "803.3953901529312\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "801.0011420249939\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "798.6182941198349\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "796.2477420568466\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "793.890762090683\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "791.5457136631012\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "789.2132810354233\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "786.893278837204\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "784.5851557254791\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "782.2902196645737\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "780.0082566738129\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "777.7378885746002\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "775.4806188344955\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "773.2357038259506\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "771.0040298700333\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "768.7834794521332\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "766.5768485069275\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "764.3829733133316\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "762.2022869586945\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "760.0334959030151\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "757.8779242038727\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "755.7360309362411\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "753.6060798168182\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "751.4881420135498\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "749.383699297905\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "747.2927709817886\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "745.212837934494\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "743.1471203565598\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "741.0940924882889\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "739.0530472993851\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "737.0258368253708\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "735.0106731653214\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "733.008198261261\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "731.0188146829605\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "729.0420898199081\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "727.0771704912186\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "725.1247673034668\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "723.1859512329102\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "721.2581770420074\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "719.3429203033447\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "717.4411560297012\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "715.5508179664612\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "713.6712735891342\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "711.8066380023956\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "709.9533840417862\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "708.11208319664\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "706.2819399833679\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "704.4656445980072\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "702.6612333059311\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "700.8681737184525\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "699.0871160030365\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "697.3195549249649\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "695.5618486404419\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "693.8176666498184\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "692.0842008590698\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "690.3637044429779\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "688.6541745662689\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "686.9571385383606\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "685.270938873291\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "683.59765458107\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "681.9349863529205\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "680.2848167419434\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "678.6447083950043\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "677.0176130533218\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "675.400384426117\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "673.7955154180527\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "672.2019733190536\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "670.6193565130234\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "669.0475505590439\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "667.487695813179\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "665.9388431310654\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "664.4003918170929\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "662.8738882541656\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "661.3575476408005\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "659.8516108989716\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "658.3574948310852\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "656.8736044168472\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "655.4006175994873\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "653.9385538101196\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "652.4858220815659\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "651.0452761650085\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "649.613316655159\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "648.1933798789978\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "646.7825275659561\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "645.382909655571\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "643.9916534423828\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "642.6128871440887\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "641.2421830892563\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "639.8828761577606\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "638.5328747034073\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "637.1926424503326\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "635.8625911474228\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "634.5420756340027\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "633.2310167551041\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "631.9303494691849\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "630.6381121873856\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "629.3564484119415\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "628.0823481082916\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "626.8194838762283\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "625.5656319856644\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "624.3204470872879\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "623.0844986438751\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "621.8580037355423\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "620.6408634185791\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "619.4314230680466\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "618.2318810224533\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "617.0411355495453\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "615.858531832695\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "614.6851364374161\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "613.5208743810654\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "612.364207983017\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "611.2175226211548\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "610.0772774219513\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "608.9471853971481\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "607.823727607727\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "606.7096254825592\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "605.6035633087158\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "604.5054513216019\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "603.4150434732437\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "602.3331186771393\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "601.2596880197525\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "600.1928336620331\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n",
      "599.13443171978\n",
      "[('and', 139)]\n",
      "[('physically', 122)]\n",
      "[('incapacitating', 33)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-3571ddcc5c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;31m# Step 3. Run the forward pass, getting log probabilities over next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;31m# words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_idxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;31m#print(log_probs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\YangY\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-173-3571ddcc5c33>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# -1 implies size inferred for that index from the size of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;31m#print(np.mean(np.mean(self.linear2.weight.data.numpy())))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output of first layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "CONTEXT_SIZE = 3\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "def get_key(word_id):\n",
    "    for key,val in word_to_ix.items():\n",
    "        if(val == word_id):\n",
    "            print(key)\n",
    "\n",
    "\n",
    "def cluster_embeddings(filename,nclusters):\n",
    "    X = np.load(filename)\n",
    "    kmeans = KMeans(n_clusters=nclusters, random_state=0).fit(X)\n",
    "    center = kmeans.cluster_centers_\n",
    "    distances = euclidean_distances(X,center)\n",
    "\n",
    "    for i in np.arange(0,distances.shape[1]):\n",
    "        word_id = np.argmin(distances[:,i])\n",
    "        print(word_id)\n",
    "        get_key(word_id)\n",
    "\n",
    "def read_data(file_path):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    data = urllib.request.urlopen(file_path)\n",
    "    data = data.read().decode('utf8')\n",
    "    tokenized_data = word_tokenize(data)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['.',',',':',';','(',')','#','--','...','\"'])\n",
    "    cleaned_words = [ i for i in tokenized_data if i not in stop_words ]\n",
    "    return(cleaned_words)\n",
    "\n",
    "\n",
    "test_sentence = \"\"\"Empathy for the poor may not come easily to people who never experienced it. They may blame the victims and insist their predicament can be overcome through determination and hard work.\n",
    "But they may not realize that extreme poverty can be psychologically and physically incapacitating — a perpetual cycle of bad diets, health care and education exacerbated by the shaming and self-fulfilling prophecies that define it in the public imagination.\n",
    "Gordon Parks — perhaps more than any artist — saw poverty as “the most savage of all human afflictions” and realized the power of empathy to help us understand it. It was neither an abstract problem nor political symbol, but something he endured growing up destitute in rural Kansas and having spent years documenting poverty throughout the world, including the United States.\n",
    "That sensitivity informed “Freedom’s Fearful Foe: Poverty,” his celebrated photo essay published in Life magazine in June 1961. He took readers into the lives of a Brazilian boy, Flavio da Silva, and his family, who lived in the ramshackle Catacumba favela in the hills outside Rio de Janeiro. These stark photographs are the subject of a new book, “Gordon Parks: The Flavio Story” (Steidl/The Gordon Parks Foundation), which accompanies a traveling exhibition co-organized by the Ryerson Image Centre in Toronto, where it opens this week, and the J. Paul Getty Museum. Edited with texts by the exhibition’s co-curators, Paul Roth and Amanda Maddox, the book also includes a recent interview with Mr. da Silva and essays by Beatriz Jaguaribe, Maria Alice Rezende de Carvalho and Sérgio Burgi.\n",
    "\"\"\".split()\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
    "\n",
    "#test_sentence = read_data('https://www.gutenberg.org/files/57884/57884-0.txt')\n",
    "\n",
    "ngrams = []\n",
    "for i in range(len(test_sentence) - CONTEXT_SIZE):\n",
    "    tup = [test_sentence[j] for j in np.arange(i + 1 , i + CONTEXT_SIZE + 1) ]\n",
    "    ngrams.append((test_sentence[i],tup))\n",
    "# print the first 3, just so you can see what they look like\n",
    "#print(ngrams)\n",
    "\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "print(\"Length of vocabulary\",len(vocab))\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "class SkipgramModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(SkipgramModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, context_size * vocab_size)\n",
    "        #self.parameters['context_size'] = context_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))  # -1 implies size inferred for that index from the size of the data\n",
    "        #print(np.mean(np.mean(self.linear2.weight.data.numpy())))\n",
    "        out1 = F.relu(self.linear1(embeds)) # output of first layer\n",
    "        out2 = self.linear2(out1)           # output of second layer\n",
    "        #print(embeds)\n",
    "        log_probs = F.log_softmax(out2, dim=1).view(CONTEXT_SIZE,-1)\n",
    "        return log_probs\n",
    "\n",
    "    def predict(self,input):\n",
    "        context_idxs = torch.tensor([word_to_ix[input]], dtype=torch.long)\n",
    "        res = self.forward(context_idxs)\n",
    "        res_arg = torch.argmax(res)\n",
    "        res_val, res_ind = res.sort(descending=True)\n",
    "        indices = [res_ind[i][0] for i in np.arange(0,3)]\n",
    "        for arg in indices:\n",
    "            print( [ (key, val) for key,val in word_to_ix.items() if val == arg ])\n",
    "\n",
    "\n",
    "    def freeze_layer(self,layer):\n",
    "        for name,child in model.named_children():\n",
    "            print(name,child)\n",
    "            if(name == layer):\n",
    "                for names,params in child.named_parameters():\n",
    "                    print(names,params)\n",
    "                    print(params.size())\n",
    "                    params.requires_grad= False\n",
    "\n",
    "    def print_layer_parameters(self):\n",
    "        for name,child in model.named_children():\n",
    "                print(name,child)\n",
    "                for names,params in child.named_parameters():\n",
    "                    print(names,params)\n",
    "                    print(params.size())\n",
    "\n",
    "    def write_embedding_to_file(self,filename):\n",
    "        for i in self.embeddings.parameters():\n",
    "            weights = i.data.numpy()\n",
    "        np.save(filename,weights)\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = SkipgramModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Freeze embedding layer\n",
    "#model.freeze_layer('embeddings')\n",
    "\n",
    "for epoch in range(550):\n",
    "    total_loss = 0\n",
    "    #------- Embedding layers are trained as well here ----#\n",
    "    #lookup_tensor = torch.tensor([word_to_ix[\"poor\"]], dtype=torch.long)\n",
    "    #hello_embed = model.embeddings(lookup_tensor)\n",
    "    #print(hello_embed)\n",
    "    # -----------------------------------------------------#\n",
    "\n",
    "    model.predict('psychologically')\n",
    "\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        #print(context,target)\n",
    "\n",
    "\n",
    "        context_idxs = torch.tensor([word_to_ix[context]], dtype=torch.long)\n",
    "        #print(\"Context id\",context_idxs)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "        #print(log_probs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        target_list = torch.tensor([word_to_ix[w] for w in target], dtype=torch.long)\n",
    "        loss = loss_function(log_probs, target_list)\n",
    "        #print(loss)\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    print(total_loss)\n",
    "    losses.append(total_loss)\n",
    "#print(losses)  # The loss decreased every iteration over the training data!\n",
    "\n",
    "#Print the model layer parameters\n",
    "#model.print_layer_parameters()\n",
    "\n",
    "#Predict the next word given n context words\n",
    "model.predict('psychologically')\n",
    "model.write_embedding_to_file('embeddings_skipgrams.npy')\n",
    "cluster_embeddings('embeddings_skipgrams.npy',5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
